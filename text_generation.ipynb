{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading my OPENAI KEY as an environment variable\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio transcription\n",
    "\n",
    "We begin by  transcribing the audio from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.41.0.windows.1\n"
     ]
    }
   ],
   "source": [
    "! git --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "audio_input_path = \"C:/Users/anand/OneDrive/Desktop/pybin_2/RentOK Task Tutorial Generation/audio/audio_to_transcribe.mp3\" \n",
    "\n",
    "model = whisper.load_model(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anand\\OneDrive\\Desktop\\pybin_2\\RentOK Task Tutorial Generation\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anand\\OneDrive\\Desktop\\pybin_2\\RentOK Task Tutorial Generation\\text_generation.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anand/OneDrive/Desktop/pybin_2/RentOK%20Task%20Tutorial%20Generation/text_generation.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mgetcwd())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anand/OneDrive/Desktop/pybin_2/RentOK%20Task%20Tutorial%20Generation/text_generation.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(audio_input_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anand/OneDrive/Desktop/pybin_2/RentOK%20Task%20Tutorial%20Generation/text_generation.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\whisper\\transcribe.py:121\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    118\u001b[0m     decode_options[\u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m mel \u001b[39m=\u001b[39m log_mel_spectrogram(audio, padding\u001b[39m=\u001b[39;49mN_SAMPLES)\n\u001b[0;32m    122\u001b[0m content_frames \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m N_FRAMES\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m decode_options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(audio, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[39m=\u001b[39m load_audio(audio)\n\u001b[0;32m    141\u001b[0m     audio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\whisper\\audio.py:59\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# fmt: on\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m run(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mstdout\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m CalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load audio: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mdecode()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    501\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    976\u001b[0m                         errread, errwrite,\n\u001b[0;32m    977\u001b[0m                         restore_signals,\n\u001b[0;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    979\u001b[0m                         start_new_session)\n\u001b[0;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\subprocess.py:1440\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1440\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1441\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1442\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1443\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1444\u001b[0m                              creationflags,\n\u001b[0;32m   1445\u001b[0m                              env,\n\u001b[0;32m   1446\u001b[0m                              cwd,\n\u001b[0;32m   1447\u001b[0m                              startupinfo)\n\u001b[0;32m   1448\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1449\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1456\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1457\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "result = model.transcribe(audio_input_path)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anand\\OneDrive\\Desktop\\pybin_2\\RentOK Task Tutorial Generation\\text_generation.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anand/OneDrive/Desktop/pybin_2/RentOK%20Task%20Tutorial%20Generation/text_generation.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "a = int(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain, TransformChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the app we are using\n",
    "\n",
    "# USER INPUT\n",
    "app_desc = \"\"\"VITian is an application built for students of VIT to access their student data. \n",
    "We can use the app to find out examination allotments.\"\"\"\n",
    "\n",
    "# Description of the actions we are performing\n",
    "\n",
    "# USER INPUT\n",
    "actions_desc = \"\"\"We begin by opening the application.\n",
    "Then we refresh the app time by pressing the refresh icon.\n",
    "Then we open the sidebar.\n",
    "Then we tap on \"Academics\"\n",
    "Then we tap on \"Exam Schedule\"\n",
    "We can now see the exam schedule and allocation.\"\"\"\n",
    "\n",
    "# Prompt template to generate teh narrator text\n",
    "topic_template = \"\"\"You are to convert the list of steps performed in the video into an organized format and properly number them. \n",
    "The output must be a python list of strings where each string is a step. Be informative and do not make up things.\n",
    "\n",
    "App details:\n",
    "```\n",
    "{app_desc}\n",
    "```\n",
    "\n",
    "Tutorial Description:\n",
    "```\n",
    "{tutorial_desc}\n",
    "```\n",
    "\n",
    "The steps being performed in the video are:\n",
    "```\n",
    "{steps}\n",
    "```\n",
    "\n",
    "Sample inputs: \n",
    "```\n",
    "App details: Gmail is an application used to send email to other people across the world.\n",
    "Tutorial Description: The tutorial shows how to view a sent email in the Gmail app.\n",
    "The steps being performed in the video are:\n",
    "We open the gmail application on our mobile device,\n",
    "we then need to navigate to the Sent emails page by tapping on the sidebar and then tapping on the Sent tab.\n",
    "Now we can select the specific email and finally, we can view the email that we have sent out.  \n",
    "```\n",
    "\n",
    "Output example:\n",
    "```\n",
    "['Open the Gmail app',\n",
    "'Open the sidebar',\n",
    "'Select Sent',\n",
    "'Select the you want to view',\n",
    "'View the email']\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, model_name = \"gpt-4\")\n",
    "system_message_prompt = SystemMessage(content=\"You are an expert at making tutorial videos and very good at defining tasks in simple terms.\")\n",
    "human_message_prompt = HumanMessagePromptTemplate(prompt=PromptTemplate(\n",
    "                                                  template=topic_template,\n",
    "                                                  input_variables=[\"app_desc\",\"tutorial_desc\", \"steps\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain to write the create the steps from the input text\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "steps_chain = LLMChain(llm=chat, prompt=chat_prompt_template, output_key='steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the steps + prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     SystemMessage(\n",
    "#         content=\"You are a narrator with experience in making tech tutorial videos.\"\n",
    "#     ),\n",
    "#     HumanMessage(\n",
    "#         content=\"\"\"You are to convert the list of steps performed in the video into an organized format and properly number them. \n",
    "# The output must be a python list of strings where each string is a step. Be informative and do not make up things.\n",
    "\n",
    "# App details:\n",
    "# ```\n",
    "# VITian is an application built for students of VIT to access their student data. \n",
    "# We can use the app to find out examination allotments.\n",
    "# ```\n",
    "\n",
    "# Tutorial Description:\n",
    "# ```\n",
    "# This is a tutorial on how to use the VITian app to view the exam schedule.\n",
    "# ```\n",
    "\n",
    "# The steps being performed in the video are:\n",
    "# ```\n",
    "# ['Open the VITian app',\n",
    "# 'Click on the refresh icon',\n",
    "# 'Open the sidebar',\n",
    "# 'Select Academics',\n",
    "# 'Select Exam Schedule',\n",
    "# 'View the exam schedule and allocation']\n",
    "# ```\n",
    "\n",
    "# Sample inputs: \n",
    "# ```\n",
    "# App details: Gmail is an application used to send email to other people across the world.\n",
    "# Tutorial Description: The tutorial shows how to view a sent email in the Gmail app.\n",
    "# The steps being performed in the video are:\n",
    "# We open the gmail application on our mobile device,\n",
    "# we then need to navigate to the Sent emails page by tapping on the sidebar and then tapping on the Sent tab.\n",
    "# Now we can select the specific email and finally, we can view the email that we have sent out.  \n",
    "# ```\n",
    "\n",
    "# Output example:\n",
    "# ```\n",
    "# ['Open the Gmail app',\n",
    "# 'Open the sidebar',\n",
    "# 'Select Sent',\n",
    "# 'Select the you want to view',\n",
    "# 'View the email']\n",
    "# ```\n",
    "# \"\"\"\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is the organized format of the steps performed in the video:\\n\\n```python\\n[\\n'Step 1: Open the VITian app',\\n'Step 2: Click on the refresh icon',\\n'Step 3: Open the sidebar',\\n'Step 4: Select Academics',\\n'Step 5: Select Exam Schedule',\\n'Step 6: View the exam schedule and allocation'\\n]\\n```\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# op.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrator Script Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the app we are using\n",
    "\n",
    "# USER INPUT\n",
    "app_desc = \"\"\"VITian is an application built for students of VIT to access their student data. \n",
    "We can use the app to find out examination allotments.\"\"\"\n",
    "\n",
    "# Description of the actions we are performing\n",
    "\n",
    "# USER INPUT\n",
    "actions_desc = \"\"\"We begin by opening the application.\n",
    "Then we refresh the app time by pressing the refresh icon.\n",
    "Then we open the sidebar.\n",
    "Then we tap on \"Academics\"\n",
    "Then we tap on \"Exam Schedule\"\n",
    "We can now see the exam schedule and allocation.\"\"\"\n",
    "\n",
    "# Prompt template to generate teh narrator text\n",
    "topic_template = \"\"\"You are to narrate a tutorial video about an app. Be informative and do not make up things.\n",
    "App details:\n",
    "```\n",
    "{app_desc}\n",
    "```\n",
    "\n",
    "Tutorial Description:\n",
    "```\n",
    "{tutorial_desc}\n",
    "```\n",
    "\n",
    "The steps being performed in the video are:\n",
    "```\n",
    "{steps}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, model_name = \"gpt-4\")\n",
    "system_message_prompt = SystemMessage(content=\"You are a narrator with experience in making tech tutorial videos.\")\n",
    "human_message_prompt = HumanMessagePromptTemplate(prompt=PromptTemplate(\n",
    "                                                  template=topic_template,\n",
    "                                                  input_variables=[\"app_desc\", \"tutorial_desc\", \"steps\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain to write the script for the narrator\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "script_chain = LLMChain(llm=chat, prompt=chat_prompt_template, output_key='script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the scripts + prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     SystemMessage(\n",
    "#         content=\"You are a narrator with experience in making tech tutorial videos.\"\n",
    "#     ),\n",
    "#     HumanMessage(\n",
    "#         content=\"\"\"You are to narrate a tutorial video about an app. Be informative and do not make up things.\n",
    "# App details:\n",
    "# ```\n",
    "# VITian is an application built for students of VIT to access their student data. \n",
    "# We can use the app to find out examination allotments.\n",
    "# ```\n",
    "\n",
    "# Tutorial Description:\n",
    "# ```\n",
    "# This is a tutorial on how to use the VITian app to view the exam schedule.\n",
    "# ```\n",
    "\n",
    "# The steps being performed in the video are:\n",
    "# ```\n",
    "# [\\n'Step 1: Open the VITian app',\\n'Step 2: Click on the refresh icon',\\n'Step 3: Open the sidebar',\\n'Step 4: Select Academics',\\n'Step 5: Select Exam Schedule',\\n'Step 6: View the exam schedule and allocation'\\n]\n",
    "# ```\n",
    "# Generate a maximum of one to two sentences per step.\n",
    "# \"\"\"\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op2 = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Background Music Starts]\\n\\n\"Hello everyone, welcome to our tutorial on how to use the VITian app to view your exam schedule. Let\\'s get started.\\n\\nStep 1: First, locate and open the VITian app on your device. This is your gateway to all your student data.\\n\\nStep 2: Once the app is open, you\\'ll see a refresh icon at the top of the screen. Click on this to ensure you have the most up-to-date information.\\n\\nStep 3: Now, let\\'s navigate to the sidebar. You can do this by swiping from the left edge of your screen or tapping on the three horizontal lines at the top left corner.\\n\\nStep 4: In the sidebar, you\\'ll find an option labeled \\'Academics\\'. Go ahead and select this to proceed.\\n\\nStep 5: Under \\'Academics\\', you\\'ll see \\'Exam Schedule\\'. Tap on this to view all upcoming exams.\\n\\nStep 6: And there you have it! You can now view your exam schedule and allocation. This will help you plan your study schedule effectively.\\n\\nThat\\'s all for this tutorial. Stay tuned for more tips and tricks on how to make the most of the VITian app. Thanks for watching.\"\\n\\n[Background Music Fades Out]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# op2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
